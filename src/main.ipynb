{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torchvision\n",
    "from typing import Union, List, Dict, Any, cast\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import Caltech256\n",
    "from torchvision.models import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a07096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definition\n",
    "class VGGNormModel(torchvision.models.VGG):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# function that init layer\n",
    "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False, norm_layer = None) -> nn.Sequential:\n",
    "    layers: List[nn.Module] = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            v = cast(int, v)\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            # v is the output channel\n",
    "            if batch_norm:\n",
    "                if norm_layer is None:\n",
    "                    raise Error(\"Please specify a norm layer\")\n",
    "                # @group if want to use this, please refer to the higher order function\n",
    "                # in the next block\n",
    "                layers += [conv2d, norm_layer(v//2, v)(), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def make_vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, norm_layer=None, num_classes = None, **kwargs: Any) -> VGG:\n",
    "    cfgs: Dict[str, List[Union[str, int]]] = {\n",
    "        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    }\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm, norm_layer=norm_layer), num_classes = num_classes, **kwargs)\n",
    "    if pretrained:\n",
    "        raise NotImplementedError()\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def vgg11_gn(pretrained: bool = False, progress: bool = True, norm_layer = None, num_classes = None, **kwargs: Any) -> VGG:\n",
    "    r\"\"\"\n",
    "    Makes the group norm version of VGG11\n",
    "    VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_.\n",
    "    The required minimum input size of the model is 32x32.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    assert num_classes is not None, \"give a number of class in accordance to dataset\"\n",
    "    return make_vgg('vgg11_bn', 'A', True, pretrained, progress, norm_layer = norm_layer, num_classes = num_classes, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group norm exp\n",
    "def get_group_norm_layer(in_channel, out_channel):\n",
    "    def fun():\n",
    "        return nn.GroupNorm(in_channel, out_channel)\n",
    "    return fun\n",
    "\n",
    "\n",
    "input = torch.randn(20, 6, 10, 10)\n",
    "# Separate 6 channels into 3 groups\n",
    "m = nn.GroupNorm(3, 6)\n",
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "#m = nn.GroupNorm(6, 6)\n",
    "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "#m = nn.GroupNorm(1, 6)\n",
    "# Activating the module\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading code\n",
    "class GreyscaleToRGBTransform(object):    \n",
    "    def __call__(self, image):  \n",
    "        if image.shape[0] == 1:\n",
    "            return transforms.Lambda(lambda x: x.repeat(3, 1, 1))(image)\n",
    "        return image\n",
    "    \n",
    "def get_torchvision_dataset(batch_size):\n",
    "    # define transforms\n",
    "    train_transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         #transforms.Lambda(lambda x: x.repeat(3, 1, 1))  if x.shape[0] == 1  else NoneTransform(),                \n",
    "         transforms.ToTensor(),\n",
    "         GreyscaleToRGBTransform(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])])\n",
    "    val_transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    # download link is broken\n",
    "    dataset = Caltech256(root=\"../data\", download=False, transform=train_transform)\n",
    "    #print(dataset)\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [24487, 6122])\n",
    "    train_set = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    val_set = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    return train_set, val_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model = model.train()\n",
    "    model = model.to(device)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = torch.as_tensor(target) # caltech256 target is int\n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.shape)\n",
    "        #print(target.shape)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args[\"dry_run\"]:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(args):\n",
    "    \n",
    "    datasets = [get_torchvision_dataset(args[\"batch_size\"])]\n",
    "    device = torch.device(args[\"device\"])\n",
    "    num_classess = [257]\n",
    "    for num_classes, (train_set, val_set) in zip(num_classess, datasets):\n",
    "        models = [vgg11_gn(norm_layer = get_group_norm_layer, num_classes = num_classes)]\n",
    "        for model in models:\n",
    "            # TODO: reload model paramter\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "            trained_model = train(args, model, args[\"device\"], train_set, optimizer, args[\"epoch\"])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # in theory load from cmd, but ... jupyter\n",
    "    args = dict()\n",
    "    args[\"device\"] = \"cuda\" \n",
    "    args[\"lr\"] = 1e-6 # learning rate\n",
    "    args[\"epoch\"] = 10\n",
    "    args[\"batch_size\"] = 2\n",
    "    args[\"log_interval\"] = 100\n",
    "    args[\"dry_run\"] = False\n",
    "    run_tests(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-stanford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-genesis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
